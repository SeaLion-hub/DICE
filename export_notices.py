#!/usr/bin/env python3
"""
export_notices.py

notices í…Œì´ë¸”ì˜ 'title', 'body_text', 'hashtags_ai' ì»¬ëŸ¼ì„
CSV (notices_export.csv) íŒŒì¼ë¡œ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:
  pip install psycopg2-binary python-dotenv
"""

import os
import csv
import psycopg2
from dotenv import load_dotenv
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")
logger = logging.getLogger("export")

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (UTF-8 ì¸ì½”ë”© ëª…ì‹œ)
load_dotenv(encoding="utf-8")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
DATABASE_URL = os.getenv("DATABASE_URL")
OUTPUT_FILE = "notices_export.csv"

def export_data():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³µì§€ì‚¬í•­ì„ ì¡°íšŒí•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    if not DATABASE_URL:
        logger.error("ì˜¤ë¥˜: DATABASE_URLì´ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # SQL ì¿¼ë¦¬: title, body_text, hashtags_ai ì¡°íšŒ
    # COALESCEë¥¼ ì‚¬ìš©í•˜ì—¬ NULL ê°’ì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ë¹ˆ ë°°ì—´ë¡œ ì²˜ë¦¬
    SQL_QUERY = """
    SELECT 
        title, 
        COALESCE(body_text, ''), 
        COALESCE(hashtags_ai, ARRAY[]::text[])
    FROM notices
    ORDER BY created_at DESC;
    """

    logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„...")
    
    try:
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (with ë¬¸ìœ¼ë¡œ ìë™ close ë³´ì¥)
        with psycopg2.connect(DATABASE_URL) as conn:
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            
            # 2. ì»¤ì„œ ìƒì„± (with ë¬¸ìœ¼ë¡œ ìë™ close ë³´ì¥)
            with conn.cursor() as cur:
                
                # 3. CSV íŒŒì¼ ì“°ê¸° (with ë¬¸ìœ¼ë¡œ ìë™ close ë³´ì¥)
                # encoding='utf-8'ë¡œ í•œêµ­ì–´ ê¹¨ì§ ë°©ì§€
                # newline=''ìœ¼ë¡œ CSV íŒŒì¼ì˜ ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ë°©ì§€
                with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    
                    # 4. í—¤ë” í–‰(Header Row) ì‘ì„±
                    writer.writerow(["title", "body_text", "hashtags"])
                    
                    logger.info("ì¿¼ë¦¬ ì‹¤í–‰...")
                    cur.execute(SQL_QUERY)
                    
                    total_rows = 0
                    
                    # 5. ë°ì´í„° í–‰(Data Rows) ì‘ì„±
                    # cur.fetchall() ëŒ€ì‹  ì´í„°ë ˆì´í„°ë¡œ ìˆœíšŒí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
                    for row in cur:
                        title, body_text, hashtags_list = row
                        
                        # 6. ë°ì´í„° ë³€í™˜
                        # hashtags_ai (text[]) ì»¬ëŸ¼ì„ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                        # ì˜ˆ: ['#í•™ì‚¬', '#ì·¨ì—…'] -> "#í•™ì‚¬,#ì·¨ì—…"
                        hashtags_str = ",".join(hashtags_list)
                        
                        # 7. CSVì— í–‰ ì“°ê¸°
                        writer.writerow([title, body_text, hashtags_str])
                        total_rows += 1

        logger.info(f"ğŸ‰ {total_rows}ê°œì˜ ê³µì§€ì‚¬í•­ì„ '{OUTPUT_FILE}'(ìœ¼)ë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

    except psycopg2.Error as db_err:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: {db_err}")
    except IOError as io_err:
        logger.error(f"íŒŒì¼ ì“°ê¸° ì˜¤ë¥˜ ({OUTPUT_FILE}): {io_err}")
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    export_data()